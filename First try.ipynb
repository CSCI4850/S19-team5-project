{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.4\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# OpenAI Gym\n",
    "import gym\n",
    "import gym_tetris\n",
    "import numpy as np\n",
    "\n",
    "# Rendering tools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [  0,   0,   0],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]]], dtype=uint8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Load the cart-pole environment\n",
    "env = gym_tetris.make('Tetris-v0')\n",
    "\n",
    "# Reinitialize the environment for an episode\n",
    "observation = env.reset()\n",
    "\n",
    "# Look at the features the agent will observe during training...\n",
    "display(observation)\n",
    "\n",
    "# Render the scene for our visualization purposes...\n",
    "plt.imshow(env.render(mode='rgb_array'))\n",
    "plt.title(\"New Episode\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(430, 330, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(430, 330, 3)\n"
     ]
    }
   ],
   "source": [
    "# Shape of the observation vectors\n",
    "display(env.observation_space.shape)\n",
    "\n",
    "# Number of possible actions\n",
    "display(env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPYAAAEICAYAAABs/QkVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFjBJREFUeJzt3XnUXVV5x/HvLwRCLGAIYBoZDEOAgksCiyEUiooFQxyC4tI4QWlaoMIqFLUGqyIu24JLwVKVMJbQKoOIi9SCGgbBYTFKwCQYEhCFGBICJBADKMnTP/Z+4eTNe9/pzju/z1pnvefsM+1z73nu2Xff855HEYGZlWVEuytgZo3nwDYrkAPbrEAObLMCObDNCuTANiuQA9usQG0PbEkzJP1vm+twiqRZw1z3HEnfaHSdGk3SFEk/bHc96iXpXEmXtbsena7fwJa0pjKsl/RiZfqjA6y7t6RXBqpARFweEe8ZasUHIukgSfMkrZV0j6Q3D2Mbo/p4DdZWpo+LiLMj4rRG13+Q9TtO0sJcl59K2rOObd0l6aW8raclXSdph0bWtx0kHSPpEUl/kHSLpJ36WXb3/DqulbRA0hG95s+UtFzSakkXS9q83evWFBGDGoDHgb8ewvJ7A68MsMzIwW5vKAMwGvg98AlgFPBpYHGt/QGnALMGsd2ngMObUedhHOO+wPPAIcBI4BxgITCixvJTgB/2s727gI/l8bHAT4DL23h8I/o6FuBc4LJBbmN8fo2m5XPiQuAn/Sz/APBvwJbAh4FngTF53rR8Tu0FbAf8Avhiu9eteSxDeKE3CmxgM+DzwGPASuDblQqtAAJYk4f9cwDdBnwTeA74XC67pbK9bwJPA6uBB4G9atTnsWp98ouyCtgHeC/wWK+T5CngbTW2NezArp5o5A8zYAawFHgG+FvgL4H5uX7n91r/ZGBRfjP/D9hxkO/Hp4DvVaa3yPs+rMbygw7sPH0mcP8g3+trgVPz+O75fZ+Rp/cFnsrjOwA35/f3WeBGYHyvOnwJuBt4CdgJ2AP4OfBCXvdiBh/Y/wjcVpkeA/wRmNDHsm8B/gCMrpTdC/xNHr8B+EJl3ruAx9u5bn9Dvd+xPwUcDRye34Q/ARfkeUcA6yJiqzw8UCmfB2wPfK3X9t4NHEA6ObYFPkL6AOjLNaRPtx49B7yQdDI92DMjItaTAmvfYRzjUG1GerN2A04E/hP4JPC2XH6ipEMAJH0IOAN4DzCO9Mn9Pz0bkjRX0hn97Et9jA/5K8dGG01N8GOBJZXi/t7rO0jHB/BWUvAfUZm+I4+PAGYBuwC75rKebfT4GHA8sDWwHPgucCfpavVV4OO96rpI0vtrHErv82AV8Dv6Pg/2BR6JiBcrZQ9Wlt1gW3n8TZK2auO6NdUb2KcAMyPi9xHxEqk5+CFJ6medxyLi0ohY1+tgIJ0s25CufETEgohYUWM73wHeL2mLPP2RXAawFemKX7WadLK0wpci4uWImJOnr4qIlRHxO1JTav9cfgrw5Yh4JCL+RHr9Dpc0DiAijoqIr9fYx4+BoyUdll+Dz5Pez9fVUe+LJT1Pam2NBv6pMq+/9/oOXgvkI0itmL/K068GdkQsj4gbI+LFiFgN/HueX3VZRCzKr8euwF8A50TEHyPiVmCDDsCI2CsibqhxPEM5DwZatvf81ZXydq1b07ADO7+hOwM3SVolaRXpijOC9OlayxP9zLsZuJzU3HpK0rckbSVpz0qH1UqAiJift3WMpG2AY4Cr83bWkD4gqrYhNeeabV1EPFOZfpF05alO97wpbwJmVV6/p0nN6ZodPD0i4iHg74FLSd/BRgGPAk/WUfeTI2IbUqvpz4E3wqDe64XACEn7kK7o3wfWSJpACvQ78na2lnSFpN/lD5Afk1puVdXz443A0/mDpMdvh3A8QzkPBlq29/xtKuXtWremYQd2pAb/UuDIiBhTGbaMiJWk71l9rtrfNiPi/IjYn9Rs3Q84PV/Repr01RPhalJz/Djg3ojoOSkW5HUBkDSC1ERdMMzDbZYnSN+lqq/f6Ii4fzArR8TVEbFPfk3OA3YEBrXuANt9APgK6WvEgO91nn8nqRn9Un7/7wBOInXsLcybnkn60Doof4AczYZfJ2DD82MZsL2kLStluwzhUHqfB68nfZj2dR4sAPbsta/9KstusK08/tuIWNPGdWuqtyk+CzhX0s4Akt4gqeenqxXAZpIG/UZImizpQEkjSR0KfwTW97PK1aTv5X/Ha81wgLnAaKXfp0eRmpR/AH422Lq0yCzgc5L2ApC0raTjBrtyfq1G5Kb7ZcA1EfFYg+p2GbCHpHdW6lrrvYYUyKfx2vfpn+TpO3PgQ2pergVWSdqe1Hnan0dIHYufl7SFpLeTOgEH63rgIEnvyYFzDvCLiHi894K5BbQ472tU7v/Yg9TBB3AVcHJuPY4FPgtc2c51+zVQ71qlN+5x+u4V/0yu2AukzpazK/PPIzUvVwGTqPSAV5ap9opPIXVyrcnrXQm8boB6/Zz0ATC2V/lBpE66F0m9jG/uZxsN7RXvNX8lMLkyfT3wqcr0DNKn8vOkZuasyrzbgDP7qc+9+bVaSfo1YXQ/yw6pVzyXnQ38bJDv9X6kq+2H4rUe8PWkFlfPMruQPlzXAL8m/Rz5ygB12JPUL7GGPnrFSV8/juvnuI7JdV4L3ALsVJl3JfD1yvQewE/zObMQeGuvbc0kXbBWA5cAm7d73VqD4tUP002XpFOASRFxSrvr0iySpgBnRMRQrnjWpVp+S6nSrY2LJC2RNLPV+zfbFIxs5c4k9dyAchSp9/ZeSXMi/fbcTvdRX29yN1hC5TdyK1tLAxs4GFgSuYNH0jWkW+baGtgRcV87998KEbGEDW84sYK1OrB3ZMPfKZ8k3etckyR3AlinWhkRHfmPMq0O7EGRdBLpN1CzTjaUm2VaqtWBvZR0B1OPnXLZBiLiElK3vq/YZsPQ6l7xe4GJknbN9zdPB+YMsI6ZDVFLr9gR8Yqk04AfkW54uCIiOu02T7Ou1/E3qLgpbh3s/og4sN2V6Evbn3lmZo3Xkb3itXR668KS/v8d31qha67YDmqzweuqKzb4atDp/AHcGbousK07tSLg/aH/mq5pipvZ4DmwzQrkwDYrkAPbrEAObLMCObDNCuTANiuQA9usQA5sswL5zjNrCd8V1lq+YrdbRP/D4jw0armeZQe7b+tKDmyzAjWtKS7pcVKOp3Wk/EwH5qRi1wITSLnAPhgRtRLbm9kwNfuK/faImFR5fMxM4NaImAjcmqfNrMFa3RSfBszO47OBY1u8f2uTGpkwrUmaGdgB/FjS/TkBAMC4iFiWx58CxvW1oqSTJN0nqfjUO2bN0Myfuw6PiKWS3gDMlfTr6syIiFpPIHXCALP6NO2KHRFL898VwPdJCfmWSxoPkP+uaNb+zTZlTbliS/ozYEREvJDHjwa+RMr6cQJwbv57YzP231UGm/+y0csNdVnrKs1qio8Dvp/vNhoJfCcifijpXuA6STNICc0+2KT9d4+Jbbwjq537tqbqmkwgPfX0rYmdLSL6fI/6Os8KeC+dCcTMWseBbVYgB7ZZgfxvm9YSBXyf7iq+YpsVyIFtViAHtlmBHNhmBXJgmxXIveLWEs2+w9G97hvyFdusQA5sswI5sM0K5MA2K5AD26xADmyzAtUV2JKukLRC0vxK2VhJcyUtzn+3zeWSdKGkJZIeknRAvZU3s77Ve8W+EpjSq6xWUoBjgIl5OAm4qM59m1kNdQV2RNwJPNuruFZSgGnAVZHcBYzpeWKplU9SUwfbUDO+Y9dKCrAj8ERluSdz2UacMMCsPk29pbS/pAADrOeEAWZ1aMYVu1ZSgKXAzpXldsplZtZgzQjsnqQAsGFSgDnA8bl3fDKwutJkN7MGqqspLulq4G3A9pKeBM4mZfnoKynATcBUUv6JtcCJ9ezbzGpzwgBrKCcM6Ay+88ysQA5sswI5sM0K5MA2K5AD26xADmyzAjmwzQrkwDYrkJ8rbi1RwM0oXcVXbLMCObDNCuTANiuQA9usQA5sswK5V9xaotH/Huxe9v75im1WoGYkDPiipKWS5uVhamXeWTlhwCJJ76xn32ZWWzMSBgBcEBGT8nATgKR9gOnAvnmdb0narM79m1kfmpEwoJZpwDUR8XJE/Ib07LOD69m/mfWtWd+xT8v5ua7oyd2FEwaYtUwzAvsiYHdgErAM+NpQNxARl0TEgZ36oDizTtfwwI6I5RGxLiLWA5fyWnPbCQPMWqThgd0r0d77gJ4e8znAdEmjJO1Kyrp5T6P3b2bNSRjwNkmTgAAeB04GiIgFkq4DFgKvAKdGxLp69m9mfXPCAGuoWgkDCuWEAWbWOg5sswI5sM0K5MA2K5AD26xADmzrXhH9D4s7+xefZnJgmxXIgW1WIAe2WYEc2GYFcmCbFciBbVYgB7ZZgfxcceteS9pdgc7lwLbuNXGT+ffQIXNT3LqX7zyryYFtVqB6M4HsLOl2SQslLZB0ei4fK2mupMX577a5XJIuzNlAHpJ0QCMOwsw2VO8V+xXgkxGxDzAZODVn/JgJ3BoRE4Fb8zTAMaSHGE4ETiI9qtjMGqzeTCDLIuKXefwF4GFSEoBpwOy82Gzg2Dw+DbgqkruAMb2eampmDdCw79iSJgD7A3cD4yJiWZ71FDAujw8qG4gzgZjVpyGBLWkr4HvAGRHxfHVepMeLDql70plAzOpTd2BL2pwU1N+OiBty8fKeJnb+uyKXOxuIWQvUmzBAwOXAwxFxfmXWHOAE4Nz898ZK+WmSrgEOAVZXmuxmQ+M7z2qqK2GApMOBnwK/Atbn4s+SvmdfB+wC/Bb4YEQ8mz8IvkHKj70WODEi+v0e7YQB3cUJAzqDM4FYQ7U0sAc6d5fQ7NtOOzawfeeZWYEc2GYFcmCbFciBbVYgB7ZZgRzYZgVyYJsVyI9Gsu7lO89q8hXbrEC+Ylv32mOA+ZvwFd1XbLMCObDNCuTANiuQA9usQA5sswI5sM0KNOzA7idZwBclLZU0Lw9TK+uclZMFLJL0zkYcgJltrJ7fsXuSBfxS0tbA/ZLm5nkXRMRXqwvnRALTgX2BNwK3SNozItbVUQfblG3Cv1MPZNhX7H6SBdQyDbgmIl6OiN+Q3paDh7t/M6utIXee9UoWcBjpSaTHA/eRrurPkYL+rspqfSYLyNs7iZQCyKw2p9GtqRHPFe+dLOAiYHdgErAM+NpQt+mEAWb1qTfb5kbJAiJieUSsi4j1wKW81tx2sgCzFqmnV7zPZAG9kuy9D5ifx+cA0yWNkrQrKePmPcPdv5nVVs937MOAjwO/kjQvl30W+LCkSaR8XY8DJwNExAJJ1wELST3qp7pH3Kw5nDDAGsqZQDqD7zwzK5AD26xADmyzAjmwzQrkwDYrkAPbrEAObLMCObDNCuTANiuQA9usQA5sswI5sM0K5MA2K5AD26xADmyzAjmwzQpU7zPPtpR0j6QHc9KAc3L5rpLuzskBrpW0RS4flaeX5PkT6j8EM+ut3iv2y8CREbEf6amkUyRNBs4jJQ3YA3gOmJGXnwE8l8svyMuZWYPVFdiRrMmTm+chgCOB63P5bODYPD4tT5Pnv0Ob0HN0zFqlEc8V3yw/zHAFMBd4FFgVEa/kRaqJAXYEngDI81cD2/WxzZMk3SfpvnrrZ7Ypqjuw8zPEJ5GeE34wsHcDtumEAWZ1aFiveESsAm4HDgXGSOp5tHE1McCrSQPy/NcDzzSqDmaW1NsrvoOkMXl8NHAUKTnf7cAH8mInADfm8Tl5mjz/tuj05x+bdaF6k/KNB2ZL2oz0IXFdRPxA0kLgGklfBh4gZQwh//1vSUuAZ0lpdc2swZwwwBrKCQM6g+88MyuQA9usQA5sswI5sM0K5MA2K5AD26xADmyzAjmwzQrkwDYrkAPbrEAObLMCObDNCuTANiuQA9usQA5sswI5sM0K1KyEAVdK+o2keXmYlMsl6cKcMOAhSQc04iDMbEP1PhqpJ2HAGkmbAz+TdHOe9+mIuL7X8scAE/NwCHBR/mtmDdSshAG1TAOuyuvdRXqa6fh66mBmG2t4woCIuDvP+tfc3L5A0qhc9mrCgKyaTMDMGqThCQMkvRk4i5Q44CBgLPCZoWzTmUDM6tOMhAFTImJZbm6/DPwXKUMIVBIGZNVkAtVtOROIWR2akTDg1z3fm3PCvWOB+XmVOcDxuXd8MrA6IpbVUwcz21izEgbcJmkHQMA84JS8/E3AVGAJsBY4sc79m1kfnDDAGsoJAzqD7zwzK5AD26xADmyzAjmwzQrkwDYrkAPbrEAObLMCObDNCuTANiuQA9usQA5sswI5sM0K5MA2K5AD26xADmyzAjmwzQrkwDYrUKMeP/yApB/k6V0l3Z2zfVwraYtcPipPL8nzJ9S7bzPrWyOu2KcDD1emzwMuiIg9gOeAGbl8BvBcLr8gL2dmTVDvU0p3At4FXJanBRwJ9KT2mU16SimkLCCz8/j1wDu0CT0cy6yV6r1ifx34Z2B9nt4OWBURr+TpaqaPV7OA5Pmr8/IbccIAs/oMO7AlvRtYERH3N7A+gBMGmNWrnueKHwa8V9JUYEtgG+A/SIn2RuarcjXTR08WkCcljQReDzxTx/7NrIZhX7Ej4qyI2CkiJgDTgdsi4qOkND8fyIudANyYx+fkafL826LTH2pu1qWa8Tv2Z4AzJS0hfYe+PJdfDmyXy88EZjZh32aGM4FYgzkTSGfwnWdmBXJgmxXIgW1WIAe2WYEc2GYFqjfxfct1ei++WSfomiv2JvQTilnduuqK7eA2G5yuuWKb2eB1wxV7DbCo3ZVokO2Ble2uRAOUchxQ37G8qZEVaaRuCOxFnXrb3lBJuq+EYynlOKCsY6lyU9ysQA5sswJ1Q2Bf0u4KNFApx1LKcUBZx/Kqjv+3TTMbum64YpvZEDmwzQrUsYEtaYqkRTlzSMc/RknSFZJWSJpfKRsraa6kxfnvtrlcki7Mx/aQpAPaV/MNSdpZ0u2SFkpaIOn0XN6Nx7KlpHskPZiP5ZxcXn62mojouAHYDHgU2A3YAngQ2Kfd9RqgzkcABwDzK2VfAWbm8ZnAeXl8KnAzIGAycHe761+p83jggDy+NfAIsE+XHouArfL45sDduY7XAdNz+SzgH/L4J4BZeXw6cG27j2HYx97uCtR4Qw4FflSZPgs4q931GkS9J/QK7EXA+Dw+nnSzDcDFwIf7Wq7TBtJTZo/q9mMBXgf8EjiEdKfZyN7nGvAj4NA8PjIvp3bXfThDpzbFX80aklUzinSTcRGxLI8/BYzL411xfLkpuj/pSteVx5KTRs4DVgBzSS3BurPVdLpODeziRLoMdM1vi5K2Ar4HnBERz1fnddOxRMS6iJhESl5xMLB3m6vUEp0a2D1ZQ3pUM4p0k+WSxgPkvytyeUcfn6TNSUH97Yi4IRd35bH0iIhVpGQWh5Kz1eRZfWWroduz1XRqYN8LTMy9l1uQOjLmtLlOw1HNftI7K8rxuUd5MrC60sxtq5wB9XLg4Yg4vzKrG49lB0lj8vhoUl/Bw2wK2Wra/SW/n86OqaQe2UeBf2l3fQZR36uBZcCfSN/bZpC+n90KLAZuAcbmZQV8Mx/br4AD213/ynEcTmpmPwTMy8PULj2WtwAP5GOZD3whl+8G3AMsAb4LjMrlW+bpJXn+bu0+huEOvqXUrECd2hQ3szo4sM0K5MA2K5AD26xADmyzAjmwzQrkwDYr0P8DVnQxr9t4DpsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the environment and perform 10 random actions\n",
    "env.reset()\n",
    "reward = 0.0\n",
    "for time in range(10):\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.title(\"%s | Time: %d | Reward: %f\" % (env.spec.id, time, reward))\n",
    "    clear_output(wait=True)\n",
    "    display(plt.gcf())\n",
    "    observation, reward, done, info = env.step(np.random.choice(env.action_space.n)) # take a random action\n",
    "    if (done):\n",
    "        break\n",
    "clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 423, 323, 64)      12352     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 416, 316, 128)     524416    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 208, 158, 128)     0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 208, 158, 128)     0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4206592)           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               538443904 \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 538,982,220\n",
      "Trainable params: 538,982,220\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 423, 323, 64)      12352     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 416, 316, 128)     524416    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 208, 158, 128)     0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 208, 158, 128)     0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4206592)           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               538443904 \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 538,982,220\n",
      "Trainable params: 538,982,220\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "# A simple multilayer architecture....\n",
    "def make_model(state_size,action_size):\n",
    "    model = keras.Sequential()\n",
    "    # Note the input size (there is only one channel - intensity)\n",
    "    # these images... if you are using color images, your would\n",
    "    # need to set the last dimension of the input_shape to -3-\n",
    "    # above and this would carry over into this cell...\n",
    "    model.add(keras.layers.Conv2D(64, kernel_size=(8, 8), activation='relu', input_shape=[state_size.shape[0],\n",
    "                            state_size.shape[1],\n",
    "                            state_size.shape[2]]))\n",
    "    model.add(keras.layers.Conv2D(128, (8, 8), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(keras.layers.Dropout(0.25))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(action_size, activation='linear'))\n",
    "    model.compile(loss='mse', optimizer=keras.optimizers.Adam(lr=0.001))\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model = make_model(env.observation_space,env.action_space.n)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -9.047846 , -19.131031 ,  -5.4079876,  -6.9576344,  -6.495033 ,\n",
       "         30.443184 ,  17.144133 ,  14.115261 ,   6.3962865, -13.115321 ,\n",
       "         26.88964  ,  13.522521 ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn our observation vector into a matrix of observations\n",
    "# with only -one- observation and run predict()\n",
    "Q = model.predict(np.expand_dims(observation,axis=0))\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example e-soft policy...\n",
    "epsilon = 0.5 # Half of the time, a random action is chosen...\n",
    "action = np.random.choice(env.action_space.n) if np.random.random() < epsilon else np.argmax(Q)\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the environment and let the agent decide!\n",
    "observation = env.reset()\n",
    "epsilon = 0.0 # No exploration!\n",
    "reward = 0.0\n",
    "for time in range(30):\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.title(\"%s | Time: %d | Reward: %f\" % (env.spec.id, time, reward))\n",
    "    clear_output(wait=True)\n",
    "    display(plt.gcf())\n",
    "    Q = model.predict(np.expand_dims(observation,axis=0)) # Compute Q\n",
    "    action = np.random.choice(env.action_space.n) if np.random.random() < epsilon else np.argmax(Q)\n",
    "    observation, reward, done, info = env.step(action) # take action!\n",
    "    if (done):\n",
    "        break\n",
    "clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1 - Replay Memory Class\n",
    "class ReplayMemory:\n",
    "    def __init__(self, memory_size, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.size = 0\n",
    "        self.maxsize = memory_size\n",
    "        self.current_index = 0\n",
    "        self.current_state = np.zeros([memory_size,env.observation_space.shape[0]])\n",
    "        self.action = [0]*memory_size # Remember, actions are integers...\n",
    "        self.reward = np.zeros([memory_size])\n",
    "        self.next_state = np.zeros([memory_size,env.observation_space.shape[0]])\n",
    "        self.done = [False]*memory_size # Boolean (terminal transition?)\n",
    "\n",
    "    def remember(self, current_state, action, reward, next_state, done):\n",
    "        # Stores a single memory item\n",
    "        self.current_state[self.current_index,:] = current_state\n",
    "        self.action[self.current_index] = action\n",
    "        self.reward[self.current_index] = reward\n",
    "        self.next_state[self.current_index,:] = next_state\n",
    "        self.done[self.current_index] = done\n",
    "        self.current_index = (self.current_index+1)%self.maxsize\n",
    "        self.size = max(self.current_index,self.size)\n",
    "    \n",
    "    def replay(self, model, target_model, num_samples, sample_size, gamma):\n",
    "        # Run replay!\n",
    "        \n",
    "        # Can't train if we don't yet have enough samples to begin with...\n",
    "        if self.size < sample_size:\n",
    "            return\n",
    "        \n",
    "        for i in range(num_samples):\n",
    "            # Select sample_size memory indices from the whole set\n",
    "            current_sample = np.random.choice(self.size,sample_size,replace=False)\n",
    "            \n",
    "            # Slice memory into training sample\n",
    "            current_state = self.current_state[current_sample,:]\n",
    "            action = [self.action[j] for j in current_sample]\n",
    "            reward = self.reward[current_sample]\n",
    "            next_state = self.next_state[current_sample,:]\n",
    "            done = [self.done[j] for j in current_sample]\n",
    "            \n",
    "            # Obtain model's current Q-values\n",
    "            model_targets = model.predict(current_state)\n",
    "            \n",
    "            # Create targets from argmax(Q(s+1,a+1))\n",
    "            # Use the target model!\n",
    "            targets = reward + gamma*np.amax(target_model.predict(next_state),axis=1)\n",
    "            # Absorb the reward on terminal state-action transitions\n",
    "            targets[done] = reward[done]\n",
    "            # Update just the relevant parts of the model_target vector...\n",
    "            model_targets[range(sample_size),action] = targets\n",
    "            \n",
    "            # Update the weights accordingly\n",
    "            model.fit(current_state,model_targets,\n",
    "                     epochs=1,verbose=0,batch_size=sample_size)\n",
    "            \n",
    "        # Once we have finished training, update the target model\n",
    "        target_model.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 423, 323, 64)      12352     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 416, 316, 128)     524416    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 208, 158, 128)     0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 208, 158, 128)     0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4206592)           0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               538443904 \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 538,982,220\n",
      "Trainable params: 538,982,220\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 423, 323, 64)      12352     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 416, 316, 128)     524416    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 208, 158, 128)     0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 208, 158, 128)     0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4206592)           0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               538443904 \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 538,982,220\n",
      "Trainable params: 538,982,220\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Full setup for the task...\n",
    "\n",
    "# For keeping track of performance\n",
    "from collections import deque\n",
    "\n",
    "# Hyperparameters\n",
    "gamma = 0.95\n",
    "epsilon = 1.0\n",
    "epsilon_decay = 0.99\n",
    "epsilon_min = 0.01\n",
    "episodes = 1000\n",
    "\n",
    "replay_iterations = 100\n",
    "replay_sample_size = 256\n",
    "\n",
    "# Peformance stats\n",
    "times_window = deque(maxlen=100)\n",
    "mean_times = deque(maxlen=episodes)\n",
    "\n",
    "# Initialize the environment and agent data structures\n",
    "env = gym_tetris.make('Tetris-v0')\n",
    "model = make_model(env.observation_space,env.action_space.n)\n",
    "target_model = make_model(env.observation_space,env.action_space.n)\n",
    "memory = ReplayMemory(10000,env.observation_space,env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "display Surface quit",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-2c495d92ca1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Perform the training!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepisode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcurrent_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Compute Q\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_episode_started_at\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/gym_tetris/tetris_env.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# return the initial screen from the game\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscreen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/gym_tetris/tetris.py\u001b[0m in \u001b[0;36mscreen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;34m\"\"\"Return the screen as a NumPy array.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msurfarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_screen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pygame/surfarray.py\u001b[0m in \u001b[0;36marray3d\u001b[0;34m(surface)\u001b[0m\n\u001b[1;32m    127\u001b[0m     method).\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnumpysf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray3d\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msurface\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpixels3d\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msurface\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pygame/_numpysurfarray.py\u001b[0m in \u001b[0;36marray3d\u001b[0;34m(surface)\u001b[0m\n\u001b[1;32m    154\u001b[0m     method).\n\u001b[1;32m    155\u001b[0m     \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msurface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0msurface_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurface\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: display Surface quit"
     ]
    }
   ],
   "source": [
    "# Perform the training!\n",
    "for episode in range(episodes):\n",
    "    current_state = env.reset()\n",
    "    for time in range(500):\n",
    "        Q = model.predict(np.expand_dims(current_state,axis=0)) # Compute Q\n",
    "        action = np.random.choice(env.action_space.n) if np.random.random() < epsilon else np.argmax(Q)\n",
    "        next_state, reward, done, info = env.step(action) # take action!\n",
    "        if done:\n",
    "            reward = -10.0\n",
    "        memory.remember(current_state,action,reward,next_state,done) # Store in memory...\n",
    "        current_state = next_state # Transition to next state!\n",
    "        if (done):\n",
    "            break\n",
    "    epsilon = epsilon * epsilon_decay if epsilon > epsilon_min else epsilon_min\n",
    "    times_window.append(time)\n",
    "    mean_time = np.mean(times_window)\n",
    "    mean_times.append(mean_time)\n",
    "    print('\\rEpisode %d/%d - time: %d, mean-time: %d, epsilon: %f'%(episode+1,episodes,time,mean_time,epsilon),end='')\n",
    "    \n",
    "    # Training...\n",
    "    memory.replay(model,target_model,replay_iterations,replay_sample_size,gamma)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.plot(mean_times)\n",
    "plt.title(\"Cart-pole Q-Learning Performance\")\n",
    "plt.xlabel(\"Episode Number\")\n",
    "plt.ylabel(\"Average # Steps [N=100]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test out the agent!\n",
    "# Initialize the environment and let the agent decide how to act!\n",
    "observation = env.reset()\n",
    "for time in range(50):\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.title(\"%s | Time: %d | Reward: %f\" % (env.spec.id, time, reward))\n",
    "    clear_output(wait=True)\n",
    "    display(plt.gcf())\n",
    "    Q = model.predict(np.expand_dims(observation,axis=0)) # Compute Q\n",
    "    action = np.argmax(Q)\n",
    "    observation, reward, done, info = env.step(action) # take action!\n",
    "    if (done):\n",
    "        break\n",
    "clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
